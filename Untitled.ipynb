{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87bdc61-bc85-41b0-ac6d-f9e46125bf01",
   "metadata": {},
   "source": [
    "Primero insertamos las librerias necesarias para el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c714fc-75c4-4aa2-af8f-d65355531ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10ccea-2a4d-462f-9f7f-474adb3c1dfd",
   "metadata": {},
   "source": [
    "Especificaremos la carpeta de entrada, que será \"input\", y la carpeta de salida, que será \"outputE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11b275-52dc-4bc7-95ea-ebdb7fb97853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "audio_input_path = os.path.join(cwd, os.path.join('audio', '_input')) \n",
    "audio_output_path = os.path.join(cwd, os.path.join('audio', '_output'))\n",
    "print(f'Directorio con los audios de entrada: {audio_input_path}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {audio_output_path}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f027d1-2a6e-4b7b-8c45-c619230ca1cf",
   "metadata": {},
   "source": [
    "Ahora ya podremos cargar los audios que necesitemos especificando su nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88f05a-1174-435c-a386-51a284eaa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(audio_input_path, 'the_last_of_us_reduced.wav')\n",
    "\n",
    "sample_rate, audio_data = wavfile.read(filename)\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "print('Datos de audio (estereo):')\n",
    "print(f'- Tamaño:     {audio_data.shape}')\n",
    "print(f'- 1º canal:   {audio_data[:5, 0]}...')\n",
    "print(f'- 2º canal:   {audio_data[:5, 1]}...')\n",
    "print(f'- Resolucion: {type(audio_data[0,0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848c174-aa92-4b64-85ca-c8d13de9f6b4",
   "metadata": {},
   "source": [
    "Crearemos un widget para escuchar el audio cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a0835-e309-4c4d-b453-e334cb7b9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9ee9b-a94e-4027-a325-5110a670e09b",
   "metadata": {},
   "source": [
    "Para pasar de estereo a mono usaremos el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facef46-1ba5-457b-882a-6d0c4bd416dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_mono = audio_data.mean(axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12b090-0ff0-4123-a5a0-0872a10da7bc",
   "metadata": {},
   "source": [
    "Comprobamos los datos una vez modificado el audio y mantenemos la misma resolución que el original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8204a9-573f-4045-b132-6fa714ad591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'- Nuevo tamaño: {new_data_mono.shape}')\n",
    "print(f'- Canal unico:  {new_data_mono[:5]}...')\n",
    "\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "print(f'- Resolucion:   {type(new_data_mono[0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd084827-bec0-4fa4-99fd-5fcdba96ea9d",
   "metadata": {},
   "source": [
    "Añadimos un nuevo widget para ecuchar el audio modificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbc546-6710-4c80-b18c-05a2b9258f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa3f48-3d87-4866-b9e1-fc16cf9ccdea",
   "metadata": {},
   "source": [
    "Procederemos a mostrar las graficas de los audios stereo y mono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3807f-352d-409f-9d01-5c69fcde3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_mono = len(audio_data)\n",
    "ampl_stereo= len(new_data_mono)\n",
    "\n",
    "t1 = np.arange(0, ampl_mono/sample_rate, 1/sample_rate)\n",
    "t2 = np.arange(0, ampl_stereo/sample_rate, 1/sample_rate)\n",
    "\n",
    "# Creamos la figura.\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Solo mostramos las primeras 50 muestras de amplitud (por claridad).\n",
    "end = 50\n",
    "\n",
    "# Señal stereo\n",
    "ax[0].plot(t1[:end], audio_data[:end], marker='X')\n",
    "ax[0].set_title(f'Audio en el dominio del tiempo muestreado a {ampl_stereo} Hz')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Señal mono\n",
    "ax[1].plot(t1[:end], new_data_mono[:end], marker='X')\n",
    "ax[1].set_title(f'Audio en el dominio del tiempo muestreado a {ampl_mono} Hz')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Mostramos la figura.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95948c86-2a76-4688-bd84-ee871340adce",
   "metadata": {},
   "source": [
    "Como podemos observar, en la gráfica del audio stereo nos aparecerean dos ondas distintas ya que este audio tiene dos canales por donde se reproduce el audio. En el segundo gráfico tenemos solo una onda ya que al ser un audio mono solo tiene un canal.\n",
    "\n",
    "Ahora procederemos a ver la frecuencia de muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789107a-7832-4c0f-bb04-6e35cefd7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Frecuencia de muestreo (estereo): {audio_data/1000} kHz')\n",
    "print(f'Frecuencia de muestreo (mono): {new_data_mono/1000} kHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe84e2-28e2-4dcd-83ce-9598205287b2",
   "metadata": {},
   "source": [
    "Para comprimir nuestro audio usaremos la Tranformada rápida de fourier. Con esto cogeremos solos los valores que se encuentre debajo de dciho valor reduciendo asi el tamaño del audio. Usaremos el audio mono para aplicarle la transforamda rápida de Fourier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57368221-0576-4581-83ab-3234834b85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La longitud del array de datos y el\n",
    "# sample rate (frecuencia de muestreo).\n",
    "n = len(new_data_mono)\n",
    "Fs = sample_rate\n",
    "\n",
    "# Working with stereo audio, there are two channels in the audio data.\n",
    "# Let's retrieve each channel seperately:\n",
    "# ch1 = np.array([data[i][0] for i in range(n)]) #channel 1\n",
    "# ch2 = np.array([data[i][1] for i in range(n)]) #channel 2\n",
    "# We can then perform a Fourier analysis on the first\n",
    "# channel to see what the spectrum looks like.\n",
    "\n",
    "# Calculando la Transformada Rapida de Fourier (FFT) en audio mono.\n",
    "ch_Fourier = np.fft.fft(new_data_mono)  # ch1\n",
    "\n",
    "# Solo miramos frecuencia por debajo de Fs/2\n",
    "# (Nyquist-Shannon) --> Spectrum.\n",
    "abs_ch_Fourier = np.absolute(ch_Fourier[:n//2])\n",
    "\n",
    "# Graficamos.\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcb737-37f5-407c-b5ca-5d5eeedc365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "# Jugamos con los valores de epsilon (CAMBIAD ESTO).\n",
    "eps = eps[2]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Calculamos el valor de corte para esta energia.\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energia del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Integral de la frecuencia --> energia del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Mascara (array booleano) que compara el valor\n",
    "# de corte con la energia del espectro.\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# La frecuencia f0 por la que cortamos el espectro.\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2)\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Graficamos.\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3115d41-49c3-4148-8fad-2e03c75e38d7",
   "metadata": {},
   "source": [
    "Según el valor de epsilon que uses, el frecuencia de corte será distinta. En este caso si usas eps(1) la frecuencia de corte sera menos que si usaramos eps(2), por tanto tendrá en cuenta menos ondas y el archivo será menor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afdd5f-a76c-482c-ad0f-dc57a4a3f87c",
   "metadata": {},
   "source": [
    "Ahora proceremos a comrpimir la onda usando downsampling usando la frecuencia de corte anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19aedd-9acc-403c-acb4-87184bf54175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los nombres de los audios comprimidos.\n",
    "wav_compressed_file = \"mono_compressed.wav\"\n",
    "\n",
    "# Calculamos el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos (slicing with stride).\n",
    "new_data = new_data_mono[::D]\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Cargamos el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(audio_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b4394-30c7-426a-8561-3d0900c58ad0",
   "metadata": {},
   "source": [
    "Mostremos los espectogramas de la banda orginal y de la comprimida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee731c-5bd2-483b-a68c-abeb27d786da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(new_data_mono, NFFT=1024, Fs=sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032ac16-cd90-411f-893e-aea9f30d95ce",
   "metadata": {},
   "source": [
    "El espectrograma del audio comprimido sigue siendo muy parecido al espectograma del audi orginal pero podemos ver como se ha reducido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9045e5-6038-4dd3-b1ce-1d262b4f3bf1",
   "metadata": {},
   "source": [
    "Los tamaños de ambos audios son los siguientes:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716380c-6f5d-4bf2-9cb3-867735b03721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'- Tamaño:     {new_data_mono.shape}')\n",
    "print(f'- Tamaño:     {new_audio_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e08b0-b2da-4b54-befb-68e42289f974",
   "metadata": {},
   "source": [
    "Vemos que el tamaño una vez comprimido el audio disminuye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109d83b-5aa1-443c-aa71-de1d226cdf04",
   "metadata": {},
   "source": [
    "Audio original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464c84e-1614-4d57-81a9-1206e5f946eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90bc5f-b33d-4f91-ba2d-cde10b089677",
   "metadata": {},
   "source": [
    "Audio original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd789b-0c0f-4777-a351-eac585525109",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data.T, rate=new_sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_audio",
   "language": "python",
   "name": "python_audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
